{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                         | 0/1659 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not load previous model; starting from scratch\n",
      "========= Epoch 1 of 10 =========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                 | 1/1659 [00:00<15:17,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.19606018066406\n",
      "asAyJruxxl; goyAiSThlr; p\n",
      "HPkrxuAi; cJcOvtBbWt; oypqdmOfCf; \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|████▊                                                                          | 101/1659 [00:44<11:19,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.662067413330078\n",
      "awxslsjudV; cuhmxhWsbv; roAmEengiv; piurvllduz; uner\n",
      "dLekd; \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█████████▌                                                                     | 201/1659 [01:27<10:40,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.658903121948242\n",
      "chuXdepryt; rotheromwz; sbhoysemrN; aiwvYentnz; drnspprmXr; \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|██████████████▎                                                                | 301/1659 [02:10<09:53,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.517515182495117\n",
      "aromtreylh; cngilissls; gryudlnode; aumQipesvt; namzicgior; \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|███████████████████                                                            | 401/1659 [02:55<09:12,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.164794921875\n",
      "afodikryma; selpryotau; trtglaurvM; noslReafop; hoaHkitvin; \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███████████████████████▊                                                       | 501/1659 [03:39<08:24,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.29253387451172\n",
      "rnerlaliso; abttrichea; gtadfleeri; ialooyBctN; lemileruyl; \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|████████████████████████▎                                                      | 511/1659 [03:44<07:44,  2.47it/s]"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../..\")\n",
    "from model.hmm import data, models, training # Generate datasets from text file\n",
    "path = \".\"\n",
    "N = 128\n",
    "config = data.read_config(N, path)\n",
    "train_dataset, valid_dataset = data.get_datasets(config, batch_size=128)\n",
    "checkpoint_path = \".\"\n",
    "\n",
    "# Initialize model\n",
    "model = models.HMM(config=config)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 10\n",
    "trainer = training.Trainer(model, config, lr=0.003)\n",
    "trainer.load_checkpoint(checkpoint_path)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(\"========= Epoch %d of %d =========\" % (epoch + 1, num_epochs))\n",
    "    train_loss = trainer.train(train_dataset, print_interval=100)\n",
    "    valid_loss = trainer.test(valid_dataset)\n",
    "    trainer.save_checkpoint(epoch, checkpoint_path)\n",
    "\n",
    "    print(\"========= Results: epoch %d of %d =========\" % (epoch + 1, num_epochs))\n",
    "    print(\"train loss: %.2f| valid loss: %.2f\\n\" % (train_loss, valid_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: loss = 397.716\n",
      "Epoch 1: loss = 43.339\n",
      "Epoch 2: loss = 36.505\n",
      "Epoch 3: loss = 35.316\n",
      "Epoch 4: loss = 34.732\n",
      "Epoch 5: loss = 34.204\n",
      "Epoch 6: loss = 34.027\n",
      "Epoch 7: loss = 33.808\n",
      "Epoch 8: loss = 33.905\n",
      "Epoch 9: loss = 33.608\n",
      "Epoch 10: loss = 33.832\n",
      "Epoch 11: loss = 33.999\n",
      "Epoch 12: loss = 33.983\n",
      "Epoch 13: loss = 33.981\n",
      "Epoch 14: loss = 33.877\n",
      "Epoch 15: loss = 33.741\n",
      "Epoch 16: loss = 33.878\n",
      "Epoch 17: loss = 33.567\n",
      "Epoch 18: loss = 33.902\n",
      "Epoch 19: loss = 34.884\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "N = len(train_dataset.Sx)\n",
    "\n",
    "embedding = torch.nn.Embedding(N, embedding_dim=256)\n",
    "lr = 1e-3\n",
    "optimizer = torch.optim.Adam(embedding.parameters(), lr=lr)\n",
    "\n",
    "batch_size = 1024\n",
    "n_epochs = 20\n",
    "print_every = 1\n",
    "k = 2 # skip-gram\n",
    "device = torch.device('cuda')\n",
    "embedding = embedding.to(device)\n",
    "for epoch_idx in range(n_epochs):\n",
    "    try:\n",
    "        batch_loss = []\n",
    "        for batch_idx, (x, T) in enumerate(train_dataset.loader):\n",
    "            x = x.cpu().numpy()\n",
    "            T = T.cpu().numpy()\n",
    "            i = np.random.randint(0, T).astype(np.int64)\n",
    "            j = np.random.randint(np.maximum(0, i-k), np.minimum(T, i+k+1)).astype(np.int64)\n",
    "            i, j = x[np.arange(len(T)), i], x[np.arange(len(T)), j]\n",
    "            i = np.concatenate([i, np.random.randint(0, N, x.shape[0])])\n",
    "            j = np.concatenate([j, np.random.randint(0, N, x.shape[0])])\n",
    "            targets = torch.tensor([np.repeat([0, 1], x.shape[0]).astype(np.float64)]).to(device)\n",
    "            i = torch.tensor(i).to(device)\n",
    "            j = torch.tensor(j).to(device)\n",
    "            optimizer.zero_grad()\n",
    "            xi = embedding(i)\n",
    "            xj = embedding(j)\n",
    "            loss = torch.binary_cross_entropy_with_logits(torch.diag(torch.matmul(xi, xj.T)), targets)\n",
    "            loss = torch.sum(loss)\n",
    "            batch_loss.append(loss.item())\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(embedding.parameters(), 0.5)\n",
    "            optimizer.step()\n",
    "        if epoch_idx % print_every == 0:\n",
    "            print(\"Epoch {}: loss = {:.3f}\".format(epoch_idx, np.mean(batch_loss)))\n",
    "    except KeyboardInterrupt:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "class HMM(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Hidden Markov Model.\n",
    "    (For now, discrete observations only.)\n",
    "    - forward(): computes the log probability of an observation sequence.\n",
    "    - viterbi(): computes the most likely state sequence.\n",
    "    - sample(): draws a sample from p(x).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config, embedding):\n",
    "        super(HMM, self).__init__()\n",
    "        self.M = config.M  # number of possible observations\n",
    "        self.N = config.N  # number of states\n",
    "        self.unnormalized_state_priors = torch.nn.Parameter(torch.randn(self.N))\n",
    "        self.transition_model = TransitionModel(self.N, embedding)\n",
    "        self.emission_model = EmissionModel(self.N, self.M)\n",
    "        self.is_cuda = torch.cuda.is_available()\n",
    "        if self.is_cuda:\n",
    "            self.cuda()\n",
    "\n",
    "    def forward(self, x, T):\n",
    "        \"\"\"\n",
    "        x : IntTensor of shape (batch size, T_max)\n",
    "        T : IntTensor of shape (batch size)\n",
    "\n",
    "        Compute log p(x) for each example in the batch.\n",
    "        T = length of each example\n",
    "        \"\"\"\n",
    "        if self.is_cuda:\n",
    "            x = x.cuda()\n",
    "            T = T.cuda()\n",
    "\n",
    "        batch_size = x.shape[0]\n",
    "        T_max = x.shape[1]\n",
    "        log_state_priors = torch.nn.functional.log_softmax(\n",
    "            self.unnormalized_state_priors, dim=0\n",
    "        )\n",
    "        log_alpha = torch.zeros(batch_size, T_max, self.N)\n",
    "        if self.is_cuda:\n",
    "            log_alpha = log_alpha.cuda()\n",
    "\n",
    "        log_alpha[:, 0, :] = self.emission_model(x[:, 0]) + log_state_priors\n",
    "        for t in range(1, T_max):\n",
    "            log_alpha[:, t, :] = self.emission_model(x[:, t]) + self.transition_model(\n",
    "                x[:,t], log_alpha[:, t - 1, :], use_max=False\n",
    "            )\n",
    "\n",
    "        log_sums = log_alpha.logsumexp(dim=2)\n",
    "\n",
    "        # Select the sum for the final timestep (each x has different length).\n",
    "        log_probs = torch.gather(log_sums, 1, T.view(-1, 1) - 1)\n",
    "        return log_probs\n",
    "\n",
    "    def sample(self, T=10):\n",
    "        state_priors = torch.nn.functional.softmax(\n",
    "            self.unnormalized_state_priors, dim=0\n",
    "        )\n",
    "        emission_matrix = torch.nn.functional.softmax(\n",
    "            self.emission_model.unnormalized_emission_matrix, dim=1\n",
    "        )\n",
    "\n",
    "        # sample initial state\n",
    "        z_t = torch.distributions.categorical.Categorical(state_priors).sample().item()\n",
    "        z = []\n",
    "        x = []\n",
    "        z.append(z_t)\n",
    "        for t in range(0, T):\n",
    "            # sample emission\n",
    "            x_t = (\n",
    "                torch.distributions.categorical.Categorical(emission_matrix[z_t])\n",
    "                .sample()\n",
    "            )\n",
    "            x.append(x_t.item())\n",
    "\n",
    "            # sample transition\n",
    "            transition_matrix = self.transition_model.log_transition_matrix(x_t.unsqueeze(0))[0]\n",
    "            z_t = (\n",
    "                torch.distributions.categorical.Categorical(transition_matrix[:, z_t])\n",
    "                .sample()\n",
    "                .item()\n",
    "            )\n",
    "            if t < T - 1:\n",
    "                z.append(z_t)\n",
    "\n",
    "        return x, z\n",
    "\n",
    "    def viterbi(self, x, T):\n",
    "        \"\"\"\n",
    "        x : IntTensor of shape (batch size, T_max)\n",
    "        T : IntTensor of shape (batch size)\n",
    "\n",
    "        Find argmax_z log p(z|x) for each (x) in the batch.\n",
    "        \"\"\"\n",
    "        if self.is_cuda:\n",
    "            x = x.cuda()\n",
    "            T = T.cuda()\n",
    "\n",
    "        batch_size = x.shape[0]\n",
    "        T_max = x.shape[1]\n",
    "        log_state_priors = torch.nn.functional.log_softmax(\n",
    "            self.unnormalized_state_priors, dim=0\n",
    "        )\n",
    "        log_delta = torch.zeros(batch_size, T_max, self.N).float()\n",
    "        psi = torch.zeros(batch_size, T_max, self.N).long()\n",
    "        if self.is_cuda:\n",
    "            log_delta = log_delta.cuda()\n",
    "            psi = psi.cuda()\n",
    "\n",
    "        log_delta[:, 0, :] = self.emission_model(x[:, 0]) + log_state_priors\n",
    "        for t in range(1, T_max):\n",
    "            max_val, argmax_val = self.transition_model(\n",
    "                x[:,t], log_delta[:, t - 1, :], use_max=True\n",
    "            )\n",
    "            log_delta[:, t, :] = self.emission_model(x[:, t]) + max_val\n",
    "            psi[:, t, :] = argmax_val\n",
    "\n",
    "        # Get the probability of the best path\n",
    "        log_max = log_delta.max(dim=2)[0]\n",
    "        best_path_scores = torch.gather(log_max, 1, T.view(-1, 1) - 1)\n",
    "\n",
    "        # This next part is a bit tricky to parallelize across the batch,\n",
    "        # so we will do it separately for each example.\n",
    "        z_star = []\n",
    "        for i in range(0, batch_size):\n",
    "            z_star_i = [log_delta[i, T[i] - 1, :].max(dim=0)[1].item()]\n",
    "            for t in range(T[i] - 1, 0, -1):\n",
    "                z_t = psi[i, t, z_star_i[0]].item()\n",
    "                z_star_i.insert(0, z_t)\n",
    "\n",
    "            z_star.append(z_star_i)\n",
    "\n",
    "        return z_star, best_path_scores\n",
    "\n",
    "\n",
    "def log_domain_matmul(log_A, log_B, use_max=False):\n",
    "    \"\"\"\n",
    "    log_A : m x n\n",
    "    log_B : n x p\n",
    "\n",
    "    output : m x p matrix\n",
    "\n",
    "    Normally, a matrix multiplication\n",
    "    computes out_{i,j} = sum_k A_{i,k} x B_{k,j}\n",
    "\n",
    "    A log domain matrix multiplication\n",
    "    computes out_{i,j} = logsumexp_k log_A_{i,k} + log_B_{k,j}\n",
    "\n",
    "    This is needed for numerical stability\n",
    "    when A and B are probability matrices.\n",
    "    \"\"\"\n",
    "    offset = 1 if len(log_A.size()) > 2 else 0\n",
    "    m = log_A.shape[0+offset]\n",
    "    n = log_A.shape[1+offset]\n",
    "    p = log_B.shape[1+offset]\n",
    "\n",
    "    log_A_expanded = torch.stack([log_A] * p, dim=2+offset)\n",
    "    log_B_expanded = torch.stack([log_B] * m, dim=0+offset)\n",
    "\n",
    "    elementwise_sum = log_A_expanded + log_B_expanded\n",
    "    out = torch.logsumexp(elementwise_sum, dim=1+offset)\n",
    "    return out\n",
    "\n",
    "    \n",
    "class TransitionModel(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    - forward(): computes the log probability of a transition.\n",
    "    - sample(): given a previous state, sample a new state.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, N, embedding, hidden_dim=256, dropout=0.5):\n",
    "        super(TransitionModel, self).__init__()\n",
    "        self.N = N  # number of states\n",
    "        self.embedding = embedding\n",
    "        self.unnormalized_transition_matrix = torch.nn.Sequential(\n",
    "            torch.nn.Linear(embedding.embedding_dim, hidden_dim),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Dropout(dropout),\n",
    "            torch.nn.Linear(hidden_dim, hidden_dim),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Dropout(dropout),\n",
    "            torch.nn.Linear(hidden_dim, N*N)\n",
    "        )\n",
    "        self.base_transition_matrix = torch.nn.Parameter(torch.randn(N, N).unsqueeze(0))\n",
    "    \n",
    "    def log_transition_matrix(self, x):\n",
    "        return torch.nn.functional.log_softmax(\n",
    "            #self.unnormalized_transition_matrix(self.embedding(x)).view(x.size(0), N, N) + \n",
    "            self.base_transition_matrix, \n",
    "            dim=1\n",
    "        )\n",
    "\n",
    "    def forward(self, x, log_alpha, use_max):\n",
    "        \"\"\"\n",
    "        log_alpha : Tensor of shape (batch size, N)\n",
    "\n",
    "        Multiply previous timestep's alphas by transition matrix (in log domain)\n",
    "        \"\"\"\n",
    "        # Each col needs to add up to 1 (in probability domain)\n",
    "        log_transition_matrix = self.log_transition_matrix(x)\n",
    "        \n",
    "        # Expand matrix to do batchwise multiplication\n",
    "        log_alpha = log_alpha.unsqueeze(-1)\n",
    "\n",
    "        # Matrix multiplication in the log domain\n",
    "        # out = genbmm.logbmm(log_alpha.unsqueeze(0).contiguous(), transition_matrix.unsqueeze(0).contiguous())[0]\n",
    "        if use_max:\n",
    "            out1, out2 = maxmul(log_transition_matrix, log_alpha)\n",
    "            return out1.transpose(0, 1), out2.transpose(0, 1)\n",
    "        else:\n",
    "            out = log_domain_matmul(log_transition_matrix, log_alpha)\n",
    "            out = out.squeeze(-1)\n",
    "            return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Epoch 1 of 10 =========\n",
      "35.482635498046875\n",
      "TxFGLhCp-k\n",
      "[57, 102, 127, 116, 115, 115, 44, 31, 89, 45]\n",
      "wHpucTsRJC\n",
      "[125, 118, 47, 61, 53, 113, 107, 120, 60, 127]\n",
      "QHfaGEvBqV\n",
      "[41, 71, 127, 113, 109, 124, 105, 50, 64, 43]\n",
      "VBQjGRADIQ\n",
      "[12, 46, 33, 105, 110, 114, 102, 55, 95, 41]\n",
      "JAjiWNyqod\n",
      "[108, 26, 19, 96, 94, 7, 22, 97, 62, 92]\n",
      "23.872852325439453\n",
      "dhSnerhtua\n",
      "[115, 108, 120, 127, 44, 56, 68, 56, 16, 27]\n",
      "pnhcuhgdvy\n",
      "[64, 114, 116, 71, 87, 67, 85, 59, 15, 101]\n",
      "adileispYm\n",
      "[108, 4, 110, 75, 16, 122, 107, 79, 46, 119]\n",
      "ceheoapntO\n",
      "[84, 120, 26, 1, 81, 55, 99, 22, 79, 50]\n",
      "iqUlacedut\n",
      "[97, 78, 36, 116, 27, 84, 35, 99, 76, 25]\n",
      "23.12369728088379\n",
      "hpbbbggmpl\n",
      "[97, 107, 41, 38, 84, 39, 98, 113, 64, 37]\n",
      "jjxdlgrlsp\n",
      "[83, 109, 113, 92, 89, 85, 112, 43, 19, 34]\n",
      "omiymogfyb\n",
      "[92, 12, 110, 3, 84, 22, 39, 58, 21, 41]\n",
      "qbFuxudhqh\n",
      "[64, 68, 57, 52, 6, 96, 99, 78, 94, 76]\n",
      "pokmiabsrw\n",
      "[41, 73, 104, 49, 7, 3, 33, 74, 111, 77]\n",
      "24.12399673461914\n",
      "sduzmprtdl\n",
      "[73, 99, 65, 20, 82, 34, 69, 106, 98, 9]\n",
      "fmylaufipu\n",
      "[118, 119, 120, 82, 48, 65, 40, 98, 62, 96]\n",
      "umuopbomuu\n",
      "[125, 91, 96, 58, 57, 75, 14, 70, 52, 26]\n",
      "sbepjmRlyg\n",
      "[126, 59, 13, 122, 97, 113, 82, 9, 81, 85]\n",
      "Pnffinblma\n",
      "[118, 114, 112, 109, 125, 127, 28, 11, 29, 27]\n",
      "21.510204315185547\n",
      "finamcbysi\n",
      "[118, 68, 123, 108, 17, 84, 37, 31, 73, 83]\n",
      "mncyecldgt\n",
      "[113, 58, 53, 120, 100, 53, 5, 126, 119, 106]\n",
      "fkhethgbpk\n",
      "[118, 104, 67, 1, 118, 124, 32, 68, 34, 104]\n",
      "stcynaaeAi\n",
      "[73, 86, 0, 21, 54, 92, 47, 108, 108, 125]\n",
      "tkcjotbcgd\n",
      "[79, 81, 57, 6, 47, 106, 33, 53, 32, 99]\n",
      "22.661907196044922\n",
      "ieiyhcvleg\n",
      "[125, 13, 110, 70, 83, 0, 105, 43, 47, 98]\n",
      "wwlumbSrmo\n",
      "[61, 61, 116, 96, 43, 37, 112, 42, 97, 92]\n",
      "smmlouwndy\n",
      "[73, 29, 115, 43, 16, 36, 61, 28, 77, 17]\n",
      "aloyqoseyt\n",
      "[48, 11, 2, 63, 94, 50, 107, 50, 70, 103]\n",
      "stwurmunml\n",
      "[126, 79, 119, 23, 80, 117, 52, 123, 29, 83]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-49e46eb4062c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"========= Epoch %d of %d =========\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m     \u001b[0mvalid_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_checkpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheckpoint_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-acfbe56ec712>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m     60\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mlog_probs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m             \u001b[0mtrain_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\acer\\miniconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m         \"\"\"\n\u001b[1;32m--> 195\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\acer\\miniconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Generate datasets from text file\n",
    "path = \".\"\n",
    "N = 128\n",
    "config = read_config(N, path)\n",
    "train_dataset, valid_dataset = get_datasets(config)\n",
    "checkpoint_path = \".\"\n",
    "\n",
    "# Initialize model\n",
    "model = HMM(config=config, embedding=embedding)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 10\n",
    "trainer = Trainer(model, config, lr=0.003)\n",
    "#trainer.load_checkpoint(checkpoint_path)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(\"========= Epoch %d of %d =========\" % (epoch + 1, num_epochs))\n",
    "    train_loss = trainer.train(train_dataset)\n",
    "    valid_loss = trainer.test(valid_dataset)\n",
    "    trainer.save_checkpoint(epoch, checkpoint_path)\n",
    "\n",
    "    print(\"========= Results: epoch %d of %d =========\" % (epoch + 1, num_epochs))\n",
    "    print(\"train loss: %.2f| valid loss: %.2f\\n\" % (train_loss, valid_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
